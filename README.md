# S3 大规模数据跨区域传输
## 项目目标

本项目主要实现 S3 大规模数据的跨区域传输，解决客户对于数据跨区域同步的业务痛点，实现（1）数据规模可量化（2）数据传输任务可分解并行加速（3）数据同步状态可跟踪（4）整体成本可量化

## 假设前提

我们首先聚焦在满足 90%客户的通用需求的场景，所以实现思路的假设前提如下：
- *（1）跨区域*：是特指 AWS 全球区域（除中国区域）之间的数据同步，又或者指AWS北京和宁夏区域之间的数据同步；没有针对 AWS 国内和 AWS全球区域之间的数据同步
- *（2）大规模数据*：是指一个 S3 存储桶里面有非常多的对象，总数达到亿+级，总数据大小 TB+ 量级； 否则，可以直接利用 AWS S3 sync 进行数据同步
- *（3）自动化*：通过 CloudFormation 实现整体方案的完全自动化部署
- *（4）用户交互*：提供 Web 交互界面；实现如下功能但并不限于（1）源存储桶数据分析（2）传输任务分解量化（3）并发传输参数建议和自定义（4）成本预估（5）目标存储桶数据差异化分析（6）大对象比如超过GB大小的对象识别和分段处理
- *（5）大对象分段*： AWS S3 API Multi-Upload 分段有限制如下，最小的分段大小为 5MB，最大的分段数为 10000；
- *（6）主要的开发环境*：Python， AWS CLI ， Boto3 ...

